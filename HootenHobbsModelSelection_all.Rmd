

#### ReadMe ####
In Fall Quarter 2018, the Converse-Gardner labs coded up parts of the Hooten and Hobbs 2015 model selection paper. This is the compilation of those efforts (one code chunk per method), with the original code.

Model selection methods include: 
- Information criteria: AIC, BIC, DIC, and D (posterior predictive loss)
- Cross validation
- Bayes factors (?)
- CPO
- Shrinkage and priors

```{r set-up}

library(jagsUI)
library(rjags)
library(coda)
library(combinat)

#set working directory
#setwd('')

############ SET UP DATA ###########
wt <- read.csv("wt.csv")
wt <- wt[1:200, ] # subset to data used by HH
#scale data
elev <-as.numeric(scale(wt$elev))
forest <- as.numeric(scale(wt$forest))

############ CREATE MODEL FILES ###########
#Intercept only model
#for abby: why 0.444 for priors?
cat(file = "wtocc_inter.txt",
    "model{
    b0 ~ dnorm(0, 0.444) 
    p ~ dbeta(1,1)
    for(i in 1:M){
    y[i]~dbin(p*z[i],J[i]) 
    
    z[i]=step(v[i]) #step() checks for x>=0, logical
    v[i]~dnorm(mu[i], 1)
    mu[i]=b0 
    }}")
#elevation only model
cat(file = "wtocc_elev.txt",
    "model{
    b0 ~ dnorm(0, 0.444)
    b1 ~ dnorm(0, 0.444)
    p ~ dbeta(1,1)
    for(i in 1:M){
    y[i]~dbin(p*z[i],J[i]) 
    
    z[i]=step(v[i])
    v[i]~dnorm(mu[i], 1)
    mu[i]=b0 + b1*elev[i]
    }}")
#forest only model
cat(file = "wtocc_for.txt",
    "model{
    b0 ~ dnorm(0, 0.444)
    b2 ~ dnorm(0, 0.444)
    p ~ dbeta(1,1)
    for(i in 1:M){
    y[i]~dbin(p*z[i],J[i]) 
    
    z[i]=step(v[i])
    v[i]~dnorm(mu[i], 1)
    mu[i]=b0+b2*forest[i]
    }}")
#full model
cat(file = "wtocc_full.txt",
    "model{
    b0 ~ dnorm(0, 0.444)
    b1 ~ dnorm(0, 0.444)
    b2 ~ dnorm(0, 0.444)
    p ~ dbeta(1,1)
    for(i in 1:M){
    y[i]~dbin(p*z[i],J[i]) 
    
    z[i]=step(v[i])
    v[i]~dnorm(mu[i], 1)
    mu[i]=b0 + b1*elev[i] + b2*forest[i]
    }}")


```

```{r information criteria}

#original author: Abby Bratt

# Create input data
M <- nrow(wt)
y <- rowSums(wt[,1:3],na.rm=T)
J <- apply(wt[,1:3], 1, function(x){length(which(!is.na(x)))}) #number of survey occasions
win.data <- list(M = M, J = J, y = y, elev = elev, forest = forest)
inits <- function(){list(p=runif(1))}

############ SET UP MCMC ###########
n.burnin = 1000
n.iter = 5000

# likelihood function; for abby: can you annotate this?
dmix <- function(y,J,p,psi){
  out=rep(0,length(y))
  zero.idx=(y==0)
  out[zero.idx]=1-psi[zero.idx]+psi[zero.idx]*(1-p)^J[zero.idx]
  out[!zero.idx]=psi[!zero.idx]*dbinom(y[!zero.idx],J[!zero.idx],p)
  out
}

############ RUN MODELS ###########
# null
params <- c("b0", "p", "mu", "y", "z")
wt.out.int <- jagsUI::jags(win.data, inits, params, "wtocc_inter.txt", 
                           n.chains=3, n.iter=n.iter, n.burnin=n.burnin,
                           parallel = TRUE, n.cores=3)
wt.out.int$summary
summary(wt.out.int)
fit.int <- wt.out.int$samples

# elevation
params <- c("b0", "b1", "p", "mu", "y", "z")
wt.out.elev <- jagsUI::jags(win.data, inits, params, "wtocc_elev.txt", 
                            n.chains=3, n.iter=5000, n.burnin=1000,
                            parallel = TRUE, n.cores=3)
wt.out.elev$summary
summary(wt.out.elev)
fit.elev <- wt.out.elev$samples

# forest
params <- c("b0", "b2", "p", "mu", "y", "z")
wt.out.forest <- jagsUI::jags(win.data, inits, params, "wtocc_for.txt", 
                              n.chains=3, n.iter=5000, n.burnin=1000, 
                              parallel = TRUE, n.cores=3)
wt.out.forest$summary
summary(wt.out.forest)
fit.forest <- wt.out.forest$samples
# full
params <- c("b0", "b1", "b2", "p", "mu", "y", "z")
wt.out.full <- jagsUI::jags(win.data, inits, params, "wtocc_full.txt", 
                            n.chains=3, n.iter=5000, n.burnin=1000, 
                            parallel = TRUE, n.cores=3)
wt.out.full$summary
summary(wt.out.full)
fit.full <- wt.out.full$samples

############ COMPUTE DIC ###########
# null
# get p's and mu's from each iteration and chain
p.int=c(fit.int[[1]][,"p"], fit.int[[2]][,"p"], fit.int[[3]][,"p"])
mu.int = rbind(fit.int[[1]][,3:202], fit.int[[2]][,3:202], fit.int[[3]][,3:202])
# mean across iterations
mean.mu.int = apply(mu.int, 2, mean)
ppd.int <- matrix(NA, nrow = (n.iter - n.burnin)*3, ncol = length(y))
for(i in 1:((n.iter - n.burnin)*3)) {
  ppd.int[i, ] <- dmix(y,J, mean(p.int), pnorm(mu.int[i, ])) # probit link
}
lppd.int = log(ppd.int)
# compute deviance evaluated at the posterior mean
D.hat.int=-2*sum(log(dmix(y,J,mean(p.int), pnorm(mean.mu.int))))
# compute posterior mean deviance
D.bar.int=mean(-2*apply(lppd.int,1,sum)) # eqn 38
pD.int=D.bar.int-D.hat.int # eqn 37
DIC.int=D.hat.int+2*pD.int # eqn 36
# print pD and DIC
c(pD.int, DIC.int)
# elev
p.elev=c(fit.elev[[1]][,"p"], fit.elev[[2]][,"p"], fit.elev[[3]][,"p"])
mu.elev = rbind(fit.elev[[1]][,4:203], fit.elev[[2]][,4:203], fit.elev[[3]][,4:203])
mean.mu.elev = apply(mu.elev, 2, mean)
ppd.elev <- matrix(NA, nrow = (n.iter - n.burnin)*3, ncol = length(y))
for(i in 1:((n.iter - n.burnin)*3)) {
  ppd.elev[i, ] <- dmix(y,J, mean(p.elev), pnorm(mu.elev[i, ]))
}
lppd.elev= log(ppd.elev)
D.hat.elev=-2*sum(log(dmix(y,J,mean(p.elev), pnorm(mean.mu.elev))))
D.bar.elev=mean(-2*apply(lppd.elev,1,sum))
pD.elev=D.bar.elev-D.hat.elev 
DIC.elev=D.hat.elev+2*pD.elev
c(pD.elev, DIC.elev)
# forest
p.forest=c(fit.forest[[1]][,"p"], fit.forest[[2]][,"p"], fit.forest[[3]][,"p"])
mu.forest = rbind(fit.forest[[1]][,4:203], fit.forest[[2]][,4:203], fit.forest[[3]][,4:203])
mean.mu.forest = apply(mu.forest, 2, mean)
ppd.forest <- matrix(NA, nrow = (n.iter - n.burnin)*3, ncol = length(y))
for(i in 1:((n.iter - n.burnin)*3)) {
  ppd.forest[i, ] <- dmix(y,J, mean(p.forest), pnorm(mu.forest[i, ]))
}
lppd.forest= log(ppd.forest)
D.hat.forest=-2*sum(log(dmix(y,J,mean(p.forest), pnorm(mean.mu.forest))))
D.bar.forest=mean(-2*apply(lppd.forest,1,sum))
pD.forest=D.bar.forest-D.hat.forest 
DIC.forest=D.hat.forest+2*pD.forest
c(pD.forest, DIC.forest)
# full
p.full=c(fit.full[[1]][,"p"], fit.full[[2]][,"p"], fit.full[[3]][,"p"])
mu.full = rbind(fit.full[[1]][,5:204], fit.full[[2]][,5:204], fit.full[[3]][,5:204])
mean.mu.full = apply(mu.full, 2, mean)
ppd.full <- matrix(NA, nrow = (n.iter - n.burnin)*3, ncol = length(y))
for(i in 1:((n.iter - n.burnin)*3)) {
  ppd.full[i, ] <- dmix(y,J, mean(p.full), pnorm(mu.full[i, ]))
}
lppd.full= log(ppd.full)
D.hat.full=-2*sum(log(dmix(y,J,mean(p.full), pnorm(mean.mu.full))))
D.bar.full=mean(-2*apply(lppd.full,1,sum))
pD.full=D.bar.full-D.hat.full 
DIC.full=D.hat.full+2*pD.full
c(pD.full, DIC.full)

############ COMPUTE WAIC ###########
# null
# -􏰇2 times the log point-wise predictive score
tmp.log=log(apply(ppd.int,2,mean)) 
tmp.sum=-2*sum(tmp.log)
pD.1.int=2*sum(tmp.log-apply(lppd.int,2,mean)) # eqn 43
pD.2.int=sum(apply(lppd.int,2,var)) # eq 44
WAIC.1.int=tmp.sum+2*pD.1.int
WAIC.2.int=tmp.sum+2*pD.2.int # this one preferred
c(pD.1.int, WAIC.1.int)
c(pD.2.int, WAIC.2.int)
# elev
tmp.log=log(apply(ppd.elev,2,mean))
tmp.sum=-2*sum(tmp.log)
pD.1.elev=2*sum(tmp.log-apply(lppd.elev,2,mean))
pD.2.elev=sum(apply(lppd.elev,2,var))
WAIC.1.elev=tmp.sum+2*pD.1.elev
WAIC.2.elev=tmp.sum+2*pD.2.elev
c(pD.1.elev, WAIC.1.elev)
c(pD.2.elev, WAIC.2.elev)
# forest
tmp.log=log(apply(ppd.forest,2,mean))
tmp.sum=-2*sum(tmp.log)
pD.1.forest=2*sum(tmp.log-apply(lppd.forest,2,mean))
pD.2.forest=sum(apply(lppd.forest,2,var))
WAIC.1.forest=tmp.sum+2*pD.1.forest
WAIC.2.forest=tmp.sum+2*pD.2.forest
c(pD.1.forest, WAIC.1.forest)
c(pD.2.forest, WAIC.2.forest)
# full
tmp.log=log(apply(ppd.full,2,mean))
tmp.sum=-2*sum(tmp.log)
pD.1.full=2*sum(tmp.log-apply(lppd.full,2,mean))
pD.2.full=sum(apply(lppd.full,2,var))
WAIC.1.full=tmp.sum+2*pD.1.full
WAIC.2.full=tmp.sum+2*pD.2.full
c(pD.1.full, WAIC.1.full)
c(pD.2.full, WAIC.2.full)

############ COMPUTE D_inf (posterior pred loss) ###########
n <- 2200 # null
pz.chain1.int = fit.int[[1]][,403:602] * fit.int[[1]][,"p"]
pz.chain2.int =  fit.int[[2]][,403:602] * fit.int[[2]][,"p"]
pz.chain3.int =  fit.int[[3]][,403:602] * fit.int[[3]][,"p"]
pz.int = rbind(pz.chain1.int, pz.chain2.int, pz.chain3.int)
# some simulated ys
y.int = matrix(NA, nrow = (n.iter - n.burnin) * 3, ncol = n)
for (i in 1:((n.iter - n.burnin) * 3)) {
  y.int[i,] <- rbinom(n,J,pz.int[i, ])
}
# means
pz.mean.int = apply(pz.int,2,mean)
y.mean.int = apply(y.int,2,mean)
sum.1=sum((y-y.mean.int)^2) # sum of (data - simulated)^2
y.var.int=apply(y.int,2,var) # var of simulated
sum.2=sum(y.var.int) # sum of vars
D.int=sum.1+sum.2 # eqn 49
D.int
# elev
pz.chain1.elev = fit.elev[[1]][,404:603] * fit.elev[[1]][,"p"]
pz.chain2.elev =  fit.elev[[2]][,404:603] * fit.elev[[2]][,"p"]
pz.chain3.elev =  fit.elev[[3]][,404:603] * fit.elev[[3]][,"p"]
pz.elev = rbind(pz.chain1.elev, pz.chain2.elev, pz.chain3.elev)
y.elev = matrix(NA, nrow = (n.iter - n.burnin) * 3, ncol = n)
for (i in 1:((n.iter - n.burnin) * 3)) {
  y.elev[i,] <- rbinom(n,J,pz.elev[i, ])
}
pz.mean.elev = apply(pz.elev,2,mean)
y.mean.elev = apply(y.elev,2,mean)
sum.1=sum((y-y.mean.elev)^2)
y.var.elev=apply(y.elev,2,var)
sum.2=sum(y.var.elev)
D.elev=sum.1+sum.2
D.elev
# forest
pz.chain1.forest = fit.forest[[1]][,404:603] * fit.forest[[1]][,"p"]
pz.chain2.forest =  fit.forest[[2]][,404:603] * fit.forest[[2]][,"p"]
pz.chain3.forest =  fit.forest[[3]][,404:603] * fit.forest[[3]][,"p"]
pz.forest = rbind(pz.chain1.forest, pz.chain2.forest, pz.chain3.forest)
y.forest = matrix(NA, nrow = (n.iter - n.burnin) * 3, ncol = n)
for (i in 1:((n.iter - n.burnin) * 3)) {
  y.forest[i,] <- rbinom(n,J,pz.forest[i, ])
}
pz.mean.forest = apply(pz.forest,2,mean)
y.mean.forest = apply(y.forest,2,mean)
sum.1=sum((y-y.mean.forest)^2)
y.var.forest=apply(y.forest,2,var)
sum.2=sum(y.var.forest)
D.forest=sum.1+sum.2
D.forest
# full
pz.chain1.full = fit.full[[1]][,405:604] * fit.full[[1]][,"p"]
pz.chain2.full =  fit.full[[2]][,405:604] * fit.full[[2]][,"p"]
pz.chain3.full =  fit.full[[3]][,405:604] * fit.full[[3]][,"p"]
pz.full = rbind(pz.chain1.full, pz.chain2.full, pz.chain3.full)
y.full = matrix(NA, nrow = (n.iter - n.burnin) * 3, ncol = n)
for (i in 1:((n.iter - n.burnin) * 3)) {
  y.full[i,] <- rbinom(n,J,pz.full[i, ])
}
pz.mean.full = apply(pz.full,2,mean)
y.mean.full = apply(y.full,2,mean)
sum.1=sum((y-y.mean.full)^2)
y.var.full=apply(y.full,2,var)
sum.2=sum(y.var.full)
D.full=sum.1+sum.2
D.full

############ REPLICATE TABLE 5 ###########
c(DIC.int, DIC.elev, DIC.forest, DIC.full)
c(WAIC.2.int, WAIC.2.elev, WAIC.2.forest, WAIC.2.full)
c(D.int, D.elev, D.forest, D.full)
# all are a smidge off but rankings same
```

```{r cross validation}

#original author: Hannah Sipe

elevation <-as.numeric(scale(wt$elev))
forestdata <- as.numeric(scale(wt$forest))

#function to run JAGs model and compute the CV score
#description of each input is described below
Jags_and_CV<-function(n,K, model, n.chains, n.iter, parallel, n.cores, n.burnin, params, inter, elev, forest, full){
  y <- rowSums(wt[,1:3],na.rm=T)
  J <- apply(wt[,1:3], 1, function(x){length(which(!is.na(x)))})
  fold_mat<-matrix(1:n, nrow=(n/K), ncol=K)
  data<-vector(mode="list", length=K)
  outs<-vector(mode="list", length=K)
  meanppd<-matrix(nrow=length(fold_mat[,1]), ncol=K)
  #choose which data to use in the model
  for(k in 1:K){
    if(inter==TRUE){
    data[[k]] <- list(M = (n-(n/K)), J = J[-fold_mat[,k]], y = y[-fold_mat[,k]])
    }else{}
    if(elev==TRUE){
      data[[k]] <- list(M = (n-(n/K)), J = J[-fold_mat[,k]], y = y[-fold_mat[,k]], 
                        elevation=elevation[-fold_mat[,k]])
    }else{}
    if(forest==TRUE){
      data[[k]] <- list(M = (n-(n/K)), J = J[-fold_mat[,k]], y = y[-fold_mat[,k]], 
                        forestdata=forestdata[-fold_mat[,k]])
    }else{}
    if(full==TRUE){
      data[[k]] <- list(M = (n-(n/K)), J = J[-fold_mat[,k]], y = y[-fold_mat[,k]], 
                        elevation=elevation[-fold_mat[,k]], forestdata=forestdata[-fold_mat[,k]])
    }else{}
    inits<-function(){list(p=runif(1))}
    #run JAGs model 
    outs[[k]] <- jags(data[[k]], inits, params, model, n.chains=n.chains, n.iter=n.iter,
                      n.burnin=n.burnin, parallel = parallel, n.cores=n.cores)
  }
  #compute the score for each model
  for(k in 1:K){
     if(inter==TRUE){
     meanppd[,k]<-dmix(y=y[fold_mat[,k]], J=J[fold_mat[,k]], p=outs[[k]]$mean$p,
                       psi=pnorm(rep(outs[[k]]$mean$b0, (n/K))))
      }else{}
    if(elev==TRUE){
      meanppd[,k]<-dmix(y=y[fold_mat[,k]], J=J[fold_mat[,k]], p=outs[[k]]$mean$p,
                        psi=pnorm(rep(outs[[k]]$mean$b0, (n/K))+elevation[fold_mat[,k]]*outs[[k]]$mean$b1))
    }else{}
    if(forest==TRUE){
      meanppd[,k]<-dmix(y=y[fold_mat[,k]], J=J[fold_mat[,k]], p=outs[[k]]$mean$p,
                        psi=pnorm(rep(outs[[k]]$mean$b0, (n/K))+ forestdata[fold_mat[,k]]*outs[[k]]$mean$b2))
    }else{}
    if(full==TRUE){
      meanppd[,k]<-dmix(y=y[fold_mat[,k]], J=J[fold_mat[,k]], p=outs[[k]]$mean$p,
                        psi=pnorm(rep(outs[[k]]$mean$b0, (n/K))+elevation[fold_mat[,k]]*outs[[k]]$mean$b1+
                        forestdata[fold_mat[,k]]*outs[[k]]$mean$b2))
    }else{}
  }
  score<- -2*sum(log(meanppd))
  
  return(list(score=score, meanppd=meanppd))#, outs=outs))
}
#function from H&H updated R code to compute the score function
dmix <- function(y,J,p,psi){
  out=rep(0,length(y))
  zero.idx=(y==0)
  out[zero.idx]=1-psi[zero.idx]+psi[zero.idx]*(1-p)^J[zero.idx]
  out[!zero.idx]=psi[!zero.idx]*dbinom(y[!zero.idx],J[!zero.idx],p)
  out
}

#definition for input to function:
#n is the total data, H&H used 200 so I did as well
#K is the number of folds, H&H used 10
#the way I wrote the function above, n/K must be a whole number
# choose the model you want to run by True or False
# n.chains, n.iter, n.burnin, n.cores, parallel (T/F) are all for running the model in JAGs

#run each model and compare scores
inter_model<-Jags_and_CV(n=200, K=10, model="wtocc_inter.txt", n.chains=3, n.iter=10000,
                          parallel=TRUE, n.cores=3, n.burnin=5000, params<-c("p","b0"),
                          inter=TRUE, elev=FALSE, forest=FALSE, full=FALSE) 
elev_model<-Jags_and_CV(n=200, K=10, model="wtocc_elev.txt", n.chains=3, n.iter=10000,
                          parallel=TRUE, n.cores=3, n.burnin=5000, params<-c("p","b0","b1"),
                          inter=FALSE, elev=TRUE, forest=FALSE, full=FALSE) 
forest_model<-Jags_and_CV(n=200, K=10, model="wtocc_for.txt", n.chains=3, n.iter=10000,
                        parallel=TRUE, n.cores=3, n.burnin=5000, params<-c("p","b0","b2"),
                        inter=FALSE, elev=FALSE, forest=TRUE, full=FALSE) 
full_model<-Jags_and_CV(n=200, K=10, model="wtocc_full.txt", n.chains=3, n.iter=10000,
                          parallel=TRUE, n.cores=3, n.burnin=5000, params<-c("p","b0","b1","b2"),
                          inter=FALSE, elev=FALSE, forest=FALSE, full=TRUE) 

#output results into a dataframe
results<-matrix(nrow=4, ncol=2)
colnames(results)<-c( "Covariates", "C-V Score")
rownames(results)<-c("M1", "M2", "M3", "M4")
results[,1]<-c("Null", "Elev", "For", "Full")
results[,2]<-c(signif(inter_model$score,4), signif(elev_model$score,4),
               signif(forest_model$score,4), signif(full_model$score,4))
as.data.frame(results)


```

```{r bayes factors?}

#original author: Robbie E.

# Create input data
M <- nrow(wt)
y <- rowSums(wt[,1:3],na.rm=T)
J <- apply(wt[,1:3], 1, function(x){length(which(!is.na(x)))})

win.data <- list(M = M, J = J, y = y, elev = elev, forest = forest)
#zinits <- ifelse(apply(y,1,sum)>0,1,0)
inits <- function(){list(p=runif(1))}
params <- c("b0", "b1", "b2", "p")
wt.out.full <- jagsUI::jags(win.data, inits, params, "wtoccfull.txt", n.chains=3, n.iter=5000,
               n.burnin=1000, parallel = TRUE, n.cores=3)


params <- c("b0", "b2", "p")
wt.out.forest <- jagsUI::jags(win.data, inits, params, "wtoccforest.txt", n.chains=3, n.iter=5000,
                    n.burnin=1000, parallel = TRUE, n.cores=3)

# Model with elevation only

params <- c("b0", "b1", "p")
wt.out.elev <- jagsUI::jags(win.data, inits, params, "wtoccelev.txt", n.chains=3, n.iter=5000,
                      n.burnin=1000, parallel = TRUE, n.cores=3)

# Intercept only model
params <- c("b0", "p", "z")
wt.out.int <- jagsUI::jags(win.data, inits, params, "wtocc_inter.txt", n.chains=3, n.iter=5000,
                      n.burnin=1000, parallel = TRUE, n.cores=3)

## Bayes factors

```

```{r CPO}

#original author: Staci A. & Nathan H.

### Conditional Predictive Ordinates ###
# probability (or density) of an observation without that data included in the model fitting
# Big CPO = very likely to include, small CPO = outlier
# Pro is that you can calc this as you fit your model by using a harmonic mean
# Con is that the harmonic mean might be unstable but there are programming ways around this, is a within-sample measure that is likely to be overly "optimistic"
# Coded in to each model's run
# All that exp(logfact())... is just dbinom(y[i],J[i],p)
# Could just do this outside of the model run as well and it would likely be faster and more elegant 

## Create empty matrix to populate with values as we find them
models <- c(1:4)
names <- c("Forest + Elev","Forest","Elev","Intercept")
cols <- c("-sum(logCPO)")
CPO_all <- matrix(NA, nrow = length(models), ncol = length(cols))
colnames(CPO_all) <- cols
rownames(CPO_all) <- names

### Full model ###

cat(file="HootinAndHobbinFULL.txt", 
"model {

  ## priors
  p ~ dbeta(1,1)
  b0 ~ dnorm(0,0.4444)
  b1 ~ dnorm(0,0.4444)
  b2 ~ dnorm(0,0.4444)
    
  for(i in 1:M){

    y[i] ~ dbin(p*z[i],J[i])

    # z[i] = step(v[i])
    # v[i] ~ dnorm(mu[i], 1)

    #Using phi() for the probit may be easier since we need psi[i] for CPO
    z[i] ~ dbin(psi[i], 1) 
    psi[i] <- phi(mu[i])         # probit link
    mu[i] = b0 + b1*elev[i] + b2*forest[i]

    ## Following H&H dmix function in occ.aux.mcmc.R script
    zero.idx[i] <- 1 - step(y[i]-0.1)   # 1 if no observations, 0 if observations
    ppd[i] <-  ((1-psi[i])+(psi[i]*(1-p)^J[i]))*zero.idx[i]  +  #if y==0, if y>0
               (1-zero.idx[i])*(psi[i]*
               (p^y[i] * (1-p)^(J[i]-y[i])* (exp(logfact(J[i]))/(exp(logfact(y[i]))*(exp(logfact(J[i]-y[i])))))))

    #monitor inverse ppd
    inv.ppd[i] <- 1/ppd[i]

  }
}",fill = TRUE)

## JAGS arguments and inits for N
data = list(M=M, J=J, elev=elev, forest=forest, y=y)
params = c('b0','b1','b2','p','inv.ppd') #'ppo.term','cpo.term')
inits = function() {list(p=runif(1), z=rep(1, M))}

nc = 3
ni = 2000
nb = 500
nthin = 1

out.full <- jagsUI::jags(data=data, inits=inits, model.file="HootinAndHobbinFULL.txt", parameters.to.save=params, n.chains=nc, n.iter=ni, n.burnin=nb, n.thin=nthin)
#plot(out.full$samples[,"b0"])

#derive CPO[i] and -sum(log(CPO)) to match H&H Table 4
outmat <- as.matrix(out.full$samples)
inv.ppd <- outmat[,grep("inv.ppd", colnames(outmat))] #matrix of inv.ppd
CPO.vec <- (dim(outmat)[1])/apply(inv.ppd,2,sum)      #CPO[i]. H&H eq(21)
CPO_all[1,1] <- -sum(log(CPO.vec))                    #-log(CPO) in H&H Table 4

#Notice, this should be similar to (identical to?)...
CPO.vec_v2 <-1/out.full$mean$inv.ppd       #posterior mean for each i
-sum(log(CPO.vec_v2))                    #should match above

save(out.full, file = "FullModel.Rdata")


### Forest only model ###

cat(file="HootinAndHobbinFOREST.txt", 
  "model {
    
  ## priors
  p ~ dbeta(1,1)
  b0 ~ dnorm(0,0.4444)
  b2 ~ dnorm(0,0.4444)
    
  for(i in 1:M){
    
    y[i] ~ dbin(p*z[i],J[i])
    
    # z[i] = step(v[i])
    # v[i] ~ dnorm(mu[i], 1)

    #Using phi() for the probit may be easier since we need psi[i] for CPO
    z[i] ~ dbin(psi[i], 1) 
    psi[i] <- phi(mu[i])         # probit link
    mu[i] = b0 + b2*forest[i]
  
    ## Following H&H dmix function in occ.aux.mcmc.R script
    zero.idx[i] <- 1 - step(y[i]-0.1)   # 1 if no observations, 0 if observations
    ppd[i] <-  ((1-psi[i])+(psi[i]*(1-p)^J[i]))*zero.idx[i]  +  #if y==0, if y>0
               (1-zero.idx[i])*(psi[i]* (p^y[i] * (1-p)^(J[i]-y[i])* (exp(logfact(J[i]))/(exp(logfact(y[i]))*(exp(logfact(J[i]-y[i])))))))
  
    #monitor inverse ppd
    inv.ppd[i] <- 1/ppd[i]
    
  }
}")

## JAGS arguments and inits for N
data = list(M=M, J=J, forest=forest, y=y)
params = c('b0','b2','p','inv.ppd')
inits = function() {list(p=runif(1), z=rep(1, M))}

nc = 3
ni = 2000
nb = 500
nthin = 1

out.forest <- jagsUI::jags(data=data, inits=inits, model.file="HootinAndHobbinFOREST.txt", parameters.to.save=params, n.chains=nc, n.iter=ni, n.burnin=nb, n.thin=nthin)

#derive CPO[i] and -sum(log(CPO)) to match H&H Table 4
outmat <- as.matrix(out.forest$samples)
inv.ppd <- outmat[,grep("inv.ppd", colnames(outmat))] #matrix of inv.ppd
CPO.vec <- (dim(outmat)[1])/apply(inv.ppd,2,sum)      #CPO[i]. H&H eq(21)
CPO_all[2,1] <- -sum(log(CPO.vec))                    #-log(CPO) in H&H Table 4

#Notice, this should be the similar to (identical to?)...
CPO.vec_v2 <-1/out.forest$mean$inv.ppd       #posterior mean for each i
-sum(log(CPO.vec_v2))                    #should match above


save(out.forest, file = "ForestModel.Rdata")


## Elevation only model ##

cat(file="HootinAndHobbinELEV.txt", 
  "model {
    
  ## priors
  p ~ dbeta(1,1)
  b0 ~ dnorm(0,0.4444)
  b1 ~ dnorm(0,0.4444)
    
  for(i in 1:M){
    
    y[i] ~ dbin(p*z[i],J[i])
    
    # z[i] = step(v[i])
    # v[i] ~ dnorm(mu[i], 1)
  
    #Using phi() for the probit may be easier since we need psi[i] for CPO
    z[i] ~ dbin(psi[i], 1) 
    psi[i] <- phi(mu[i])         # probit link
    mu[i] = b0 + b1*elev[i]
  
    ## Following H&H dmix function in occ.aux.mcmc.R script
    zero.idx[i] <- 1 - step(y[i]-0.1)   # 1 if no observations, 0 if observations
    ppd[i] <-  ((1-psi[i])+(psi[i]*(1-p)^J[i]))*zero.idx[i]  +  #if y==0, if y>0
               (1-zero.idx[i])*(psi[i]* (p^y[i] * (1-p)^(J[i]-y[i])* (exp(logfact(J[i]))/(exp(logfact(y[i]))*(exp(logfact(J[i]-y[i])))))))
  
    #monitor inverse ppd
    inv.ppd[i] <- 1/ppd[i]
    
  }
}")

## JAGS arguments and inits for N
data = list(M=M, J=J, elev=elev, y=y)
params = c('b0','b1','p','inv.ppd')
inits = function() {list(p=runif(1), z=rep(1,M))}

nc = 3
ni = 2000
nb = 500
nthin = 1

out.elev <- jagsUI::jags(data=data, inits=inits, model.file="HootinAndHobbinELEV.txt", parameters.to.save=params, n.chains=nc, n.iter=ni, n.burnin=nb, n.thin=nthin)

#derive CPO[i] and -sum(log(CPO)) to match H&H Table 4
outmat <- as.matrix(out.elev$samples)
inv.ppd <- outmat[,grep("inv.ppd", colnames(outmat))] #matrix of inv.ppd
CPO.vec <- (dim(outmat)[1])/apply(inv.ppd,2,sum)      #CPO[i]. H&H eq(21)
CPO_all[3,1] <- -sum(log(CPO.vec))                    #-log(CPO) in H&H Table 4

#Notice, this should be the similar to (identical to?)...
CPO.vec_v2 <-1/out.elev$mean$inv.ppd       #posterior mean for each i
-sum(log(CPO.vec_v2))                    #should match above

save(out.elev, file = "ElevModel.Rdata")


## Intercept only model ##

cat(file="HootinAndHobbinINT.txt", 
  "model {
    
  ## priors
  p ~ dbeta(1,1)
  b0 ~ dnorm(0,0.4444)
    
  for(i in 1:M){
    
    y[i] ~ dbin(p*z[i],J[i])
    
    # z[i] = step(v[i])
    # v[i] ~ dnorm(mu[i], 1)
  
    #Using phi() for the probit may be easier since we need psi[i] for CPO
    z[i] ~ dbin(psi[i], 1) 
    psi[i] <- phi(mu[i])         # probit link
    mu[i] = b0
  
    ## Following H&H dmix function in occ.aux.mcmc.R script
    zero.idx[i] <- 1 - step(y[i]-0.1)   # 1 if no observations, 0 if observations
    ppd[i] <-  ((1-psi[i])+(psi[i]*(1-p)^J[i]))*zero.idx[i]  +  #if y==0, if y>0
               (1-zero.idx[i])*(psi[i]* (p^y[i] * (1-p)^(J[i]-y[i])* (exp(logfact(J[i]))/(exp(logfact(y[i]))*(exp(logfact(J[i]-y[i])))))))
  
    #monitor inverse ppd
    inv.ppd[i] <- 1/ppd[i]
    
  }
}")

## JAGS arguments and inits for N
data = list(M=M, J=J, y=y)
params = c('b0','p', 'inv.ppd')
inits = function() {list(p=runif(1), z=rep(1,M))}

nc = 3
ni = 2000
nb = 500
nthin = 1

out.int <- jagsUI::jags(data=data, inits=inits, model.file="HootinAndHobbinINT.txt", parameters.to.save=params, n.chains=nc, n.iter=ni, n.burnin=nb, n.thin=nthin)

#derive CPO[i] and -sum(log(CPO)) to match H&H Table 4
outmat <- as.matrix(out.int$samples)
inv.ppd <- outmat[,grep("inv.ppd", colnames(outmat))] #matrix of inv.ppd
CPO.vec <- (dim(outmat)[1])/apply(inv.ppd,2,sum)      #CPO[i]. H&H eq(21)
CPO_all[4,1] <- -sum(log(CPO.vec))                    #-log(CPO) in H&H Table 4

#Notice, this should be the similar to (identical to?)...
CPO.vec_v2 <-1/out.int$mean$inv.ppd       #posterior mean for each i
-sum(log(CPO.vec_v2))                    #should match above

save(out.int, file = "IntModel.Rdata")


as.data.frame(CPO_all)


```

```{r shrinkage and priors}

#original author: Robbie E.

####models with the original prior #######
#Intercept only model
cat(file = "wtocc_inter.txt",
    "model{
    b0 ~ dnorm(0, 0.444)
    p ~ dbeta(1,1)
    for(i in 1:M){
    y[i]~dbin(p*z[i],J[i]) 
    
    z[i] ~ dbin(psi[i], 1)
    psi[i] = phi(mu[i])
    mu[i]=b0 
    }}")
#elevation only model
cat(file = "wtocc_elev.txt",
    "model{
    b0 ~ dnorm(0, 0.444)
    b1 ~ dnorm(0, 0.444)
    p ~ dbeta(1,1)
    for(i in 1:M){
    y[i]~dbin(p*z[i],J[i]) 
    
    z[i] ~ dbin(psi[i], 1)
    psi[i] = phi(mu[i])
    mu[i]=b0 + b1*elevation[i]
    } }")
#forest only model
cat(file = "wtocc_for.txt",
    "model{
    b0 ~ dnorm(0, 0.444)
    b2 ~ dnorm(0, 0.444)
    p ~ dbeta(1,1)
    for(i in 1:M){
    y[i]~dbin(p*z[i],J[i]) 
    
    z[i] ~ dbin(psi[i], 1)
    psi[i] = phi(mu[i])
    mu[i]=b0+b2*forestdata[i]
    }}")
#full model
cat(file = "wtocc_full.txt",
    "model{
    b0 ~ dnorm(0, 0.444)
    b1 ~ dnorm(0, 0.444)
    b2 ~ dnorm(0, 0.444)
    p ~ dbeta(1,1)
    for(i in 1:M){
    y[i]~dbin(p*z[i],J[i]) 
    
    z[i] ~ dbin(psi[i], 1)
    psi[i] = phi(mu[i])
    mu[i]=b0 + b1*elevation[i] + b2*forestdata[i]
    }}")

#### Models with vague normal priors on b ####
#Intercept only model
cat(file = "wtocc_inter_vague.txt",
    "model{
    b0 ~ dnorm(0, 0.01)
    p ~ dbeta(1,1)
    for(i in 1:M){
    y[i]~dbin(p*z[i],J[i]) 
    
    z[i] ~ dbin(psi[i], 1)
    psi[i] = phi(mu[i])
    mu[i]=b0 
    }}")
#elevation only model
cat(file = "wtocc_elev_vague.txt",
    "model{
    b0 ~ dnorm(0, 0.01)
    b1 ~ dnorm(0, 0.01)
    p ~ dbeta(1,1)
    for(i in 1:M){
    y[i]~dbin(p*z[i],J[i]) 
    
    z[i] ~ dbin(psi[i], 1)
    psi[i] = phi(mu[i])
    mu[i]=b0 + b1*elevation[i]
    } }")
#forest only model
cat(file = "wtocc_for_vague.txt",
    "model{
    b0 ~ dnorm(0, 0.01)
    b2 ~ dnorm(0, 0.01)
    p ~ dbeta(1,1)
    for(i in 1:M){
    y[i]~dbin(p*z[i],J[i]) 
    
    z[i] ~ dbin(psi[i], 1)
    psi[i] = phi(mu[i])
    mu[i]=b0+b2*forestdata[i]
    }}")
#full model
cat(file = "wtocc_full_vague.txt",
    "model{
    b0 ~ dnorm(0, 0.01)
    b1 ~ dnorm(0, 0.01)
    b2 ~ dnorm(0, 0.01)
    p ~ dbeta(1,1)
    for(i in 1:M){
    y[i]~dbin(p*z[i],J[i]) 
    
    z[i] ~ dbin(psi[i], 1)
    psi[i] = phi(mu[i])
    mu[i]=b0 + b1*elevation[i] + b2*forestdata[i]
    }}")

#### Models with uniform priors on b ####
#Intercept only model
cat(file = "wtocc_inter_unif.txt",
    "model{
    b0 ~ dunif(-10, 10)
    p ~ dbeta(1,1)
    for(i in 1:M){
    y[i]~dbin(p*z[i],J[i]) 
    
    z[i] ~ dbin(psi[i], 1)
    psi[i] = phi(mu[i])
    mu[i]=b0 
    }}")
#elevation only model
cat(file = "wtocc_elev_unif.txt",
    "model{
    b0 ~ dunif(-10, 10)
    b1 ~ dunif(-10, 10)
    p ~ dbeta(1,1)
    for(i in 1:M){
    y[i]~dbin(p*z[i],J[i]) 
    
    z[i] ~ dbin(psi[i], 1)
    psi[i] = phi(mu[i])
    mu[i]=b0 + b1*elevation[i]
    } }")
#forest only model
cat(file = "wtocc_for_unif.txt",
    "model{
    b0 ~ dunif(-10, 10)
    b2 ~ dunif(-10, 10)
    p ~ dbeta(1,1)
    for(i in 1:M){
    y[i]~dbin(p*z[i],J[i]) 
    
    z[i] ~ dbin(psi[i], 1)
    psi[i] = phi(mu[i])
    mu[i]=b0+b2*forestdata[i]
    }}")
#full model
cat(file = "wtocc_full_unif.txt",
    "model{
    b0 ~ dunif(-10, 10)
    b1 ~ dunif(-10, 10)
    b2 ~ dunif(-10, 10)
    p ~ dbeta(1,1)
    for(i in 1:M){
    y[i]~dbin(p*z[i],J[i]) 
    
    z[i] ~ dbin(psi[i], 1)
    psi[i] = phi(mu[i])
    mu[i]=b0 + b1*elevation[i] + b2*forestdata[i]
    }}")

#### Models with Laplace priors on b - like lasso ####
#Intercept only model
cat(file = "wtocc_inter_laplace.txt",
    "model{
    b0 ~ dnorm(0, 0.444)
    p ~ dbeta(1,1)
    for(i in 1:M){
    y[i]~dbin(p*z[i],J[i]) 
    
    z[i] ~ dbin(psi[i], 1)
    psi[i] = phi(mu[i])
    mu[i]=b0 
    }}")
#elevation only model
cat(file = "wtocc_elev_laplace.txt",
    "model{
    b0 ~ dnorm(0, 0.444)
    tau ~ dunif(0.0001, 10)
    b1 ~ ddexp(0, tau)
    p ~ dbeta(1,1)
    for(i in 1:M){
    y[i]~dbin(p*z[i],J[i]) 
    
    z[i] ~ dbin(psi[i], 1)
    psi[i] = phi(mu[i])
    mu[i]=b0 + b1*elevation[i]
    } }")
#forest only model
cat(file = "wtocc_for_laplace.txt",
    "model{
    b0 ~ dnorm(0, 0.444)
    tau ~ dunif(0.0001, 10)
    b2 ~ ddexp(0, tau)
    p ~ dbeta(1,1)
    for(i in 1:M){
    y[i]~dbin(p*z[i],J[i]) 
    
    z[i] ~ dbin(psi[i], 1)
    psi[i] = phi(mu[i])
    mu[i]=b0+b2*forestdata[i]
    }}")
#full model
cat(file = "wtocc_full_laplace.txt",
    "model{
    b0 ~ dnorm(0, 0.444)
    tau ~ dunif(0.001, 10)
    b1 ~ ddexp(0, tau)
    b2 ~ ddexp(0, tau)
    p ~ dbeta(1,1)
    for(i in 1:M){
    y[i]~dbin(p*z[i],J[i]) 
    
    z[i] ~ dbin(psi[i], 1)
    psi[i] = phi(mu[i])
    mu[i]=b0 + b1*elevation[i] + b2*forestdata[i]
    }}")

#### Fit and compare models with different priors ####
## "normal" normal
M <- nrow(wt)
y <- rowSums(wt[,1:3],na.rm=T)
J <- apply(wt[,1:3], 1, function(x){length(which(!is.na(x)))})

win.data <- list(M = M, J = J, y = y, elevation = elevation, forestdata = forestdata)
#zinits <- ifelse(apply(y,1,sum)>0,1,0)
inits <- function(){list(p=runif(1), z=rep(1,M))}

params <- c("b0", "p")
wt.out.inter <- jagsUI::jags(win.data, inits, params, "wtocc_inter.txt", n.chains=3, n.iter=5000,
                            n.burnin=1000, parallel = TRUE, n.cores=3)

params <- c("b0", "b1", "p")
wt.out.elev <- jagsUI::jags(win.data, inits, params, "wtocc_elev.txt", n.chains=3, n.iter=5000,
                            n.burnin=1000, parallel = TRUE, n.cores=3)

params <- c("b0", "b2", "p")
wt.out.for <- jagsUI::jags(win.data, inits, params, "wtocc_for.txt", n.chains=3, n.iter=5000,
                            n.burnin=1000, parallel = TRUE, n.cores=3)

params <- c("b0", "b1", "b2", "p")
wt.out.full <- jagsUI::jags(win.data, inits, params, "wtocc_full.txt", n.chains=3, n.iter=5000,
                            n.burnin=1000, parallel = TRUE, n.cores=3)

## vague normal
params <- c("b0", "p")
wt.out.inter.vague <- jagsUI::jags(win.data, inits, params, "wtocc_inter_vague.txt", n.chains=3, n.iter=5000,
                             n.burnin=1000, parallel = TRUE, n.cores=3)

params <- c("b0", "b1", "p")
wt.out.elev.vague <- jagsUI::jags(win.data, inits, params, "wtocc_elev_vague.txt", n.chains=3, n.iter=5000,
                            n.burnin=1000, parallel = TRUE, n.cores=3)

params <- c("b0", "b2", "p")
wt.out.for.vague <- jagsUI::jags(win.data, inits, params, "wtocc_for_vague.txt", n.chains=3, n.iter=5000,
                           n.burnin=1000, parallel = TRUE, n.cores=3)

params <- c("b0", "b1", "b2", "p")
wt.out.full.vague <- jagsUI::jags(win.data, inits, params, "wtocc_full_vague.txt", n.chains=3, n.iter=5000,
                            n.burnin=1000, parallel = TRUE, n.cores=3)

## uniform
params <- c("b0", "p")
wt.out.inter.unif <- jagsUI::jags(win.data, inits, params, "wtocc_inter_unif.txt", n.chains=3, n.iter=5000,
                             n.burnin=1000, parallel = TRUE, n.cores=3)

params <- c("b0", "b1", "p")
wt.out.elev.unif <- jagsUI::jags(win.data, inits, params, "wtocc_elev_unif.txt", n.chains=3, n.iter=5000,
                            n.burnin=1000, parallel = TRUE, n.cores=3)

params <- c("b0", "b2", "p")
wt.out.for.unif <- jagsUI::jags(win.data, inits, params, "wtocc_for_unif.txt", n.chains=3, n.iter=5000,
                           n.burnin=1000, parallel = TRUE, n.cores=3)

params <- c("b0", "b1", "b2", "p")
wt.out.full.unif <- jagsUI::jags(win.data, inits, params, "wtocc_full_unif.txt", n.chains=3, n.iter=5000,
                            n.burnin=1000, parallel = TRUE, n.cores=3)

## Laplace
params <- c("b0", "p")
wt.out.inter.lap <- jagsUI::jags(win.data, inits, params, "wtocc_inter_laplace.txt", n.chains=3, n.iter=5000,
                             n.burnin=1000, parallel = TRUE, n.cores=3)

params <- c("b0", "b1", "p")
wt.out.elev.lap <- jagsUI::jags(win.data, inits, params, "wtocc_elev_laplace.txt", n.chains=3, n.iter=5000,
                            n.burnin=1000, parallel = TRUE, n.cores=3)

params <- c("b0", "b2", "p")
wt.out.for.lap <- jagsUI::jags(win.data, inits, params, "wtocc_for_laplace.txt", n.chains=3, n.iter=5000,
                           n.burnin=1000, parallel = TRUE, n.cores=3)

params <- c("b0", "b1", "b2", "p")
wt.out.full.lap <- jagsUI::jags(win.data, inits, params, "wtocc_full_laplace.txt", n.chains=3, n.iter=5000,
                            n.burnin=1000, parallel = TRUE, n.cores=3)

## Comparison
cbind(wt.out.inter$mean, wt.out.inter.vague$mean, wt.out.inter.unif$mean, wt.out.inter.lap$mean)
cbind(wt.out.elev$mean, wt.out.elev.vague$mean, wt.out.elev.unif$mean, wt.out.elev.lap$mean)
cbind(wt.out.for$mean, wt.out.for.vague$mean, wt.out.for.unif$mean, wt.out.for.lap$mean)
cbind(wt.out.full$mean, wt.out.full.vague$mean, wt.out.full.unif$mean, wt.out.full.lap$mean)

```
